// ----------------------SHADERS-----------------------------
flat basic.vs flat.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs

light basic.vs light.fs
light_singlepass basic.vs light_singlepass.fs
sh2debug basic.vs sh2debug.fs
//fbo basic.vs fbo.fs

gbuffers basic.vs gbuffers.fs
showAlpha quad.vs showAlpha.fs // es de 2D-> quad. muestra solo el 4ยบ componente
deferred quad.vs deferred.fs
deferred_ws basic.vs deferred_ws.fs

ssao quad.vs ssao.fs 
applyHDRgamma quad.vs applyHDRgamma.fs

probe basic.vs probe.fs //basic ya q es una esfera que lo vamos a proyectar
irradiance_sh quad.vs irradiance_sh.fs 
skybox basic.vs skybox.fs

volumetric_rendering quad.vs volumetric_rendering.fs

reflection_probe basic.vs reflection_probe.fs
reflection_forward basic.vs reflection_forward.fs 

reflection_fbo quad.vs reflection_fbo.fs

decal basic.vs decal.fs
// Depth of field
compute_coc quad.vs compute_coc.fs
dof quad.vs dof.fs

// ----------------------GET PARAMETERS-----------------------------
\get_parm_from_vs

varying vec3 v_position; 
varying vec3 v_world_position; 
varying vec3 v_normal; 
varying vec2 v_uv; 
varying vec4 v_color;

\get_textures_uniforms

uniform sampler2D u_color_texture;
uniform sampler2D u_emissive_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_metallic_roughness_texture;
uniform sampler2D u_occlusion_texture;

uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;

\get_lights_uniforms
uniform int u_light_type; 

uniform vec3 u_light_vector; 
uniform vec3 u_light_color;
uniform vec3 u_light_position;

uniform float u_light_intensity;
uniform float u_light_maxdist; 
uniform float u_light_cone_angle;
uniform float u_light_area_size;

uniform float u_light_spotCosineCutoff;
uniform float u_light_spotExponent;

\get_shadow_uniforms

uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;
uniform sampler2D u_shadow_map;
uniform bool u_cast_shadows;
uniform bool u_show_shadows;

\get_irradiance_uniforms

uniform vec3 u_irr_end;
uniform vec3 u_irr_start;
uniform float u_irr_normal_distance;
uniform vec3 u_irr_delta;
uniform vec3 u_irr_dims;
uniform float u_num_probes; // LO pongo como float porque tenemos que sumarlo con otro float y, OpenGL 2.1, se queja de esto
uniform sampler2D u_probes_texture;

// ----------------------LIGHT COMPUTATION-----------------------------

\compute_light_phong

if( u_light_type == 0){ // directional

		L = normalize(-u_light_vector);
		NdotL = max( dot(N,L), 0.0);
		light += NdotL * u_light_color * u_light_intensity * shadow_factor;
}
else{
	L = normalize(u_light_position - v_world_position);
	NdotL = max( dot(N,L), 0.0);
	float spotFactor = 1.0;
	if( u_light_type == 2) {
		float spotCosine = dot( normalize( u_light_vector), -L);
		spotCosine = max(spotCosine, 0.0); 
		if ( spotCosine >= u_light_spotCosineCutoff ){
			spotFactor = pow( spotCosine , u_light_spotExponent ) ;
		}
		else{
			spotFactor = 0.0; //if it's outsite
		}
	}
	light += NdotL * spotFactor * att_factor * u_light_color * u_light_intensity * shadow_factor;
}

// ----------------------GET FUNCTIONS-----------------------------

// ----------------------FOR LIGHT-----------------------------

\get_lights_functions

float compute_attfactor(vec3 u_light_position, vec3 v_world_position, float u_light_maxdistance){
	
	// Distance from the light to the object
	float light_to_point_distance = distance(u_light_position, v_world_position);

	float att_factor = clamp(u_light_maxdistance - light_to_point_distance, 0.0, u_light_maxdistance);

	// Normalizing attenuation factor
	att_factor /= u_light_maxdistance;

	// Ignoring negative values
	//att_factor = max(att_factor, 0.0);
	att_factor = pow(att_factor, 2.0);
	return att_factor;

}

//att adjusts by distance
float attenuation_by_distance( vec3 u_light_position, vec3 v_world_position )
{
	//compute distance
	float light_distance = length(u_light_position - v_world_position );

	//compute a linear attenuation factor
	float att_factor = 1.0 / light_distance;
	return att_factor;

} 

// att adjusts by maximum distance
float attenuation_ranged( vec3 u_light_position, vec3 v_world_position, float u_light_maxdist){

	//compute distance
	float light_distance = length(u_light_position - v_world_position );

	//compute a linear attenuation factor
	float att_factor = u_light_maxdist - light_distance;

	//normalize factor btw [0,1]
	att_factor /= u_light_maxdist;

	//ignore negative values, if pass max_dist, then it's 0.0
	att_factor = max( att_factor, 0.0 );
	
	// quadratic factor
	return att_factor *= att_factor;
	
}

// ----------------------UTILS-------------------------------------

\get_functions_utils

// fs to compute normal maps
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}

// assume N, the interpolated vertex normal and WP the world position
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
	// conv from [0,1] to [-1,1]
	normal_pixel = normal_pixel * 255./127. - 128./127.;
	// a rotation matrix
	//N.x = -N.x;
	mat3 TBN = cotangent_frame(N, WP, uv); 
	// conv tg space to world space 
	return normalize(TBN * normal_pixel); 
}

// ----------------------SHADOW-------------------------------------

\get_shadow_functions

float outsideShadowmap(vec2 shadow_uv, float real_depth){
    //for directional lights

    //it is outside on the sides
    if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
        if( u_light_type == 1)
            return 1.0;
        else
            return 0.0;

    //it is before near or behind far plane
    if(real_depth < 0.0 || real_depth > 1.0)
        return 1.0;

	return 1.0;	

}

float get_shadow_factor( vec3 pos, mat4 u_shadow_viewproj, float u_shadow_bias, sampler2D shadowmap, bool u_cast_shadows, bool u_show_shadows){
	if(!u_cast_shadows || !u_show_shadows){
		return 1.0;	
	}

	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewproj * vec4(pos,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;

	//read depth from depth buffer in [0..+1] non-linear
	float shadow_depth = texture2D( shadowmap, shadow_uv).x;

	//compute final shadow factor by comparing
	float shadow_factor = outsideShadowmap(shadow_uv, real_depth);

	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		shadow_factor = 0.0;

	return shadow_factor;	
}

// ----------------------FOR TEXTURE-----------------------------

\get_textures_functions

#include "get_functions_utils"
vec3 get_normal(vec3 v_normal, vec3 v_world_position, vec2 v_uv, sampler2D u_normal_texture){
	
	
	vec3 N = normalize( v_normal ); //normals from vertex
	vec3 normal_pixel = texture2D( u_normal_texture, v_uv ).xyz; // normals from texture (normalmap) in tangent space
	
	vec3 n = vec3(0.0);

	if(normal_pixel == vec3(0.0)){ // Because we have set that the meshes without normal texture have a black texture (0.0 valued texture)
		n = N;
	} 
	else {
		n = perturbNormal( N, v_world_position, v_uv, normal_pixel );
	}
	
	return  normalize(n); // It returns nomal values in range [-1...1]
}

vec4 get_uvs( vec2 v_uv)
{
	return vec4( v_uv , 1.0, 1.0);
}

vec4 get_occlusion( vec2 v_uv, sampler2D u_metallic_roughness_texture, sampler2D u_occlusion_texture)
{
	float oc_fac = texture2D( u_occlusion_texture, v_uv ).x;
	float mr_fac = texture2D( u_metallic_roughness_texture , v_uv).x ; 
	oc_fac *= mr_fac;
	return vec4( oc_fac, oc_fac, oc_fac, 1.0 ); 
}


// ----------------------PBR functions-----------------------------

\get_PBR_functions

#define PI 0.3183098861837697

// Normal Distribution Function using GGX Distribution
float D_GGX ( const  float NoH, const  float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}

vec3 F_Schlick( const float VoH, const vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + ( vec3(1.0) - f0) * f;
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH ){

	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX( NoH, a );

	
	// Fresnel Function
	//float F = F_Schlick( LoH, f0 );
	vec3 F = F_Schlick( LoH, f0 );
	
	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	
	return spec;
}





vec3 get_diffspecular_light( vec3 L, vec3 u_light_vector, vec3 u_light_position, vec3 u_camera_position, vec3 N, float metalness, float roughness, vec3 color, float NoL ){
	

	vec3 V = normalize(  u_camera_position - u_light_position);

	vec3 H = normalize( L + V );

	float NoH = max( dot(N,H) , 0.0); 
	float NoV = max( dot(N,V) , 0.0);
	float LoH = max( dot(L,H) , 0.0);

	//compute fresnel factor
	//float fresnel = 1.0 - max( NoV , 0.0 );
	//make it less linear...
	//fresnel = pow( fresnel, 2.0 );
	vec3 f0 = mix( vec3(0.5), color.xyz, metalness );

	//metallic materials do not have diffuse. They are inv prop
	vec3 diffuseColor = (1.0 - metalness) * color.xyz;

	//compute the specular //reflectand
	vec3 Fr_d = specularBRDF( roughness, f0 , NoH, NoV, NoL, LoH );

	vec3 Fd_d = diffuseColor * NoL; 

	//add diffuse and specular reflection = direct light
	vec3 direct = Fd_d + Fr_d ;

	//shadow_factor = F
	//compute how much light received the pixel
	vec3 lightParams = u_light_color * u_light_intensity;

	//modulate direct light by light received
	return direct * lightParams; 

	//return diffuseColor;
}

\get_gamma_functions

vec3 degamma(vec3 c)
{
	//return pow(c,vec3(2.2));
	return c*=c ;
}

vec3 gamma(vec3 c)
{
	//return pow(c,vec3(1.0/2.2));
	return sqrt(c);
}

float gamma_factor = 2.0;

vec3 simpleReinhardToneMapping(vec3 color)
{
	float exposure = 1.5;
	color *= exposure/( ( 1.0 + color )/exposure);
	color = pow(color, vec3(1. / gamma_factor ));
	return color;
}

vec3 linearToneMapping(vec3 color)
{
	float exposure = 1.;
	color = clamp(exposure * color, 0., 1.);
	color = pow(color, vec3(1. / gamma_factor));
	return color;
}


//----------------------Dithering functions-----------------------------

\get_dithering_function

float dither4x4(vec2 position, float brightness)
{
	//creamos un patron de 4x4, 16 possibles casos:	
  int x = int(mod(position.x, 4.0));
  int y = int(mod(position.y, 4.0));
  int index = x + y * 4;
  float limit = 0.0;

  if (x < 8) {
	  //y a partir del thr, indicamos que ese pixel se activa o no 
    if (index == 0) limit = 0.0625;
    if (index == 1) limit = 0.5625;
    if (index == 2) limit = 0.1875;
    if (index == 3) limit = 0.6875;
    if (index == 4) limit = 0.8125;
    if (index == 5) limit = 0.3125;
    if (index == 6) limit = 0.9375;
    if (index == 7) limit = 0.4375;
    if (index == 8) limit = 0.25;
    if (index == 9) limit = 0.75;
    if (index == 10) limit = 0.125;
    if (index == 11) limit = 0.625;
    if (index == 12) limit = 1.0;
    if (index == 13) limit = 0.5;
    if (index == 14) limit = 0.875;
    if (index == 15) limit = 0.375;
  }

  return brightness < limit ? 0.0 : 1.0;
}


// -------------------------------------------------------------------------------------------------------------------------
\basic.vs


attribute vec3 a_vertex;
attribute vec3 a_normal;
attribute vec2 a_coord;
attribute vec4 a_color;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;
varying vec4 v_color;

uniform float u_time;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
		
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

// -------------------------------------------------------------------------------------------------------------------------
\quad.vs



attribute vec3 a_vertex;
attribute vec2 a_coord;
varying vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4( a_vertex, 1.0 );
}



// -------------------------------------------------------------------------------------------------------------------------
\flat.fs

//uniform vec4 u_color;
//out vec4 FragColor;

void main()
{
	gl_FragColor = vec4(1.0);
}

// -------------------------------------------------------------------------------------------------------------------------
\texture.fs

#include "get_parm_from_vs"

uniform vec4 u_color;
uniform sampler2D u_color_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

//out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_color_texture, v_uv );

	if(color.a < u_alpha_cutoff) //si el pixel tiene una alpha mas peq, no lo pintamos, ni en z-buffer
	// es para cortarlo, como si no hubiera existido. 
		discard;
	
	gl_FragColor = color;
}

// -------------------------------------------------------------------------------------------------------------------------

\sh2debug.fs

varying vec3 v_world_position; 
varying vec3 v_normal; 
varying vec2 v_uv; 

uniform int u_texture_type;
uniform sampler2D u_normal_texture;
uniform sampler2D u_metallic_roughness_texture;
uniform sampler2D u_occlusion_texture;
uniform mat4 u_model;

//out vec4 FragColor;

#include "get_textures_functions"

void main()
{
    vec4 color;
    
    if (u_texture_type == 0){
        vec3 normal = get_normal( v_normal,  v_world_position, v_uv, u_normal_texture);
		color = abs(vec4(normal,1.0)); // abs value only to visualize.

    }
    else if (u_texture_type == 1){
        color = get_occlusion( v_uv, u_metallic_roughness_texture, u_occlusion_texture);
    }
    else{
        color = get_uvs(v_uv);
    }
    
	gl_FragColor = color;
}


// -------------------------------------------------------------------------------------------------------------------------

\light.fs

uniform vec4 u_color;
uniform vec3 u_emissive_factor;
uniform float u_alpha_cutoff;
uniform vec3 u_ambient_light;
uniform vec3 u_camera_position;
//uniform bool u_rendering_reflection_flag;
//uniform samplerCube u_reflection_texture;

#include "get_parm_from_vs"
#include "get_lights_uniforms"
#include "get_lights_functions"
#include "get_textures_uniforms"
#include "get_textures_functions"
#include "get_shadow_functions"
#include "get_shadow_uniforms"

//out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	
	//vec3 color = ( u_color.xyz ); //-----G
	color *= texture2D( u_color_texture, uv );
	
	if(color.a < u_alpha_cutoff) 
		discard;
	
	vec4 occ = get_occlusion( v_uv, u_metallic_roughness_texture, u_occlusion_texture);
	vec3 light = vec3(0.0) ;
	light += u_ambient_light * occ.xyz ;
	
	vec3 N = get_normal( v_normal,  v_world_position, v_uv, u_normal_texture);

	
	

	vec3 L = vec3(0.0);
	float NdotL = 0.0;
	float att_factor = compute_attfactor(  u_light_position, v_world_position, u_light_maxdist);
	float shadow_factor = get_shadow_factor( v_world_position, u_shadow_viewproj, u_shadow_bias, u_shadow_map, u_cast_shadows, u_show_shadows);
	
	#include "compute_light_phong"
	
	/*

	vec3 V = v_world_position - u_camera_position;
	vec3 R = reflect(V,N);

		vec3 N = normalize(v_normal);
	vec3 V = v_world_position - u_camera_position;
	vec3 R = reflect(V,N);
	//compute the reflection 
	// vec3 reflection = baseColor * textureLod( u_environment_texture, R, roughness * 5.0 ).xyz;

	gl_FragColor = texture( u_texture, R); //vec4(1,0,0,1);//
	
	*/


	color.xyz *= light;
	color.xyz += u_emissive_factor * ( texture2D(u_emissive_texture, uv ).xyz );
	gl_FragColor = color;
	//gl_FragColor = texture( u_texture, R);
}

//--------------------------------------------------------------------------------------------------------------------------

\light_singlepass.fs

uniform vec4 u_color;
uniform vec3 u_emissive_factor;
uniform float u_alpha_cutoff;
uniform vec3 u_ambient_light;

const int MAX_LIGHTS = 8;
uniform int u_num_lights;
uniform int u_light_type[MAX_LIGHTS];
uniform vec3 u_light_color[MAX_LIGHTS];
uniform vec3 u_light_position[MAX_LIGHTS];
uniform vec3 u_light_vector[MAX_LIGHTS];
uniform float u_light_intensity[MAX_LIGHTS];
uniform float u_light_maxdist[MAX_LIGHTS];
uniform float u_light_spotExponent[MAX_LIGHTS];
uniform float u_light_spotCosineCutoff[MAX_LIGHTS];

#include "get_parm_from_vs"
#include "get_lights_functions"
#include "get_textures_functions"
#include "get_textures_uniforms"

//out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_color_texture, uv );

	if(color.a < u_alpha_cutoff) 
		discard;

	vec3 light = vec3(0.0);
	vec4 occ = get_occlusion( v_uv, u_metallic_roughness_texture, u_occlusion_texture);
	light += u_ambient_light * occ.xyz ;
	
	vec3 N = get_normal( v_normal,  v_world_position, v_uv, u_normal_texture);
	
	vec3 L = vec3(0.0);
	float NdotL = 0.0;
	float att_factor = 0.0;
	for (int i = 0; i < MAX_LIGHTS; ++i){

		if( i < u_num_lights){
			att_factor = compute_attfactor(  u_light_position[i] , v_world_position, u_light_maxdist[i] );
	
			if( u_light_type[i] == 0){ // directional
				L = normalize( -u_light_vector[i]) ;
				NdotL = max( dot(N,L), 0.0) ;
				light += NdotL * u_light_color[i] * u_light_intensity[i] ;
			}
			else if(u_light_type[i] == 1){ // Is failing with att_factor. Maybe the problem is on the function or the parameters
				L = normalize(u_light_position[i] - v_world_position);
				NdotL = max( dot(N,L), 0.0);
				light += NdotL * u_light_color[i] * u_light_intensity[i] ; // We have removed the att_factor
			}
			else if(u_light_type[i] == 2){
				L = normalize(u_light_position[i] - v_world_position);
				NdotL = max( dot(N,L), 0.0);
				float spotCosine = dot( normalize(u_light_vector[i]) , -L );
				spotCosine = max(spotCosine, 0.0);
				if ( spotCosine >= u_light_spotCosineCutoff[i] ){
					float spotFactor = pow( spotCosine , u_light_spotExponent[i] );
					light += NdotL * spotFactor * att_factor * u_light_color[i] * u_light_intensity[i] ;	 
				}
			}
		}
	}
	
	color.xyz *= light;
	color.xyz += u_emissive_factor * texture2D(u_emissive_texture, uv ).xyz ;
	gl_FragColor = color;

}

// -------------------------------------------------------------------------------------------------------------------------
//\fbo.fs

// -------------------------------------------------------------------------------------------------------------------------

\gbuffers.fs

uniform vec4 u_color;
uniform vec3 u_emissive_factor;
uniform float u_alpha_cutoff;
//uniform sampler2D u_ao_texture;
uniform bool u_use_dither;

#include "get_textures_uniforms"
#include "get_parm_from_vs"
#include "get_textures_functions"
#include "get_dithering_function"

//layout(location = 0) out vec4 FragColor;
//layout(location = 1) out vec4 NormalColor;
//layout(location = 2) out vec4 ExtraColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_color_texture, uv );
	
	//discard some pixels depending on the pixel screen position and its transparency
	if( color.a < 0.9 && floor(mod(gl_FragCoord.x,2.0)) != floor(mod(gl_FragCoord.y,2.0)) ) 
		discard;

	if(u_use_dither && color.a < 0.9 ){
		float dither_factor = dither4x4( gl_FragCoord.xy , color.a );
		if( dither_factor == 0.0 )
			discard;
	}

	//-----save each textures to each buffers---
	color *= texture2D( u_color_texture, uv );
	vec3 emissive = u_emissive_factor * texture2D(u_emissive_texture, uv ).xyz ;
	vec3 N = get_normal( v_normal,  v_world_position, v_uv, u_normal_texture); //N is in range [-1...1]
	//vec3 N = normalize(v_normal);	
	vec4 metallic_roughness = texture2D( u_metallic_roughness_texture, v_uv);
	
	color.a = metallic_roughness.b; //alpha = metalness
	
	gl_FragData[0] = color;
	gl_FragData[1] = vec4( N * 0.5 + vec3(0.5) , metallic_roughness.g ); //alpha = roughness. Also, se that we save N in range [0...1]
	gl_FragData[2] = vec4( emissive,  metallic_roughness.x ); //alpha = occ 
}

//--------------------------------------------------------------------------------------------------------------------------

\showAlpha.fs



varying vec2 v_uv;
uniform sampler2D u_texture;
//out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = texture2D( u_texture, uv );
	
	gl_FragColor = vec4( color.a ); 

}

// -------------------------------------------------------------------------------------------------------------------------

\deferred.fs

//varying vec2 v_uv;
uniform vec3 u_camera_position;
uniform mat4 u_inverse_viewprojection;
uniform vec3 u_ambient_light;
uniform vec2 u_iRes;
uniform sampler2D u_ao_texture;
uniform bool u_ao_show;

#include "get_textures_uniforms"
#include "get_textures_functions"
#include "get_lights_uniforms"
#include "get_lights_functions"
#include "get_PBR_functions"
#include "get_gamma_functions"
#include "get_shadow_functions"
#include "get_shadow_uniforms"

//layout(location=0) out vec4 FragColor;
//out vec4 FragColor;

void main()
{
	// we can extract uvs from pixel screenpos
	vec2 uv = gl_FragCoord.xy * u_iRes.xy ;
	//vec2 uv = v_uv ;

	//-----read each textures from gbuffers---
	vec4 albedo = texture2D(u_color_texture, uv);
	vec4 normal = texture2D(u_normal_texture, uv);
	vec4 extra = texture2D(u_extra_texture, uv);
	vec4 depth = texture2D(u_depth_texture, uv);
	
	//ignore pixels in the background
	if(depth.x >= 1.0)
		discard;

	//normals mush be converted from 0..1 to -1..+1
	vec3 N = normalize( normal.xyz * 2.0 - 1.0 ); 
	
	//reconstruct world position from depth and inv. viweproj
	float depth_fact = depth.x ;
	vec4 screen_pos = vec4( uv.x *2.0 -1.0, uv.y * 2.0 -1.0, depth_fact*2.0-1.0, 1.0 ); // conv todo de -1 a 1
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w ;


	vec3 light = vec3(0.0);
	vec3 color = vec3(0.0);
	color = degamma(albedo.xyz); // convertir a lineal 
	color = (albedo.xyz); // convertir a lineal 
	
	vec3 L = vec3(0.0);

	float metalness = albedo.a; 
	float roughness = normal.a;
	float att_factor =  compute_attfactor(  u_light_position, world_position, u_light_maxdist);
	float shadow_factor = get_shadow_factor( world_position, u_shadow_viewproj, u_shadow_bias, u_shadow_map, u_cast_shadows, u_show_shadows);
	float ao_factor = 1.0;
	if( u_ao_show ){
		ao_factor = texture2D(u_ao_texture, uv).x ;
		ao_factor = pow( ao_factor, 2.0 );
	}

	light +=  u_ambient_light * extra.a * ao_factor;
	
	if( u_light_type == 0){ // directional

		L = normalize(-u_light_vector);
		float NoL = max( dot(N,L) , 0.0);
		//vec3 diffspecular_light = get_diffspecular_light(  L ,  u_light_vector,  u_light_position,  u_camera_position,  N,  metalness, roughness ,  color,  NoL );

		light += NoL * u_light_color * u_light_intensity * shadow_factor;

	}
	color.xyz *= light;
	color.xyz += extra.xyz ; // degamma( extra.xyz); //emissive light
		
	gl_FragData[0] = vec4(color, 1.0 ) ;
	
}


// -------------------------------------------------------------------------------------------------------------------------


\deferred_ws.fs

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;

#include "get_parm_from_vs"
#include "get_lights_uniforms"
#include "get_lights_functions"
#include "get_textures_uniforms"
#include "get_textures_functions"
#include "get_PBR_functions"
#include "get_gamma_functions"

#include "get_shadow_functions"
#include "get_shadow_uniforms"

//layout(location=0) out vec4 FragColor;
//out vec4 FragColor;


void main()
{
	// we can extract uvs from pixel screenpos
	vec2 uv = gl_FragCoord.xy * u_iRes.xy ;
	
	//-----read each textures from gbuffers---
	vec4 albedo = texture2D(u_color_texture, uv);
	vec4 normal = texture2D(u_normal_texture, uv);
	vec4 extra = texture2D(u_extra_texture, uv);
	vec4 depth = texture2D(u_depth_texture, uv);
	
	//ignore pixels in the background
	if(depth.x >= 1.0)
		discard;
	

	//normals mush be converted from 0..1 to -1..+1
	vec3 N = normalize( normal.xyz * 2.0 - 1.0 ); 
	
	//reconstruct world position from depth and inv. viweproj
	float depth_fact = depth.x ;
	vec4 screen_pos = vec4( uv.x *2.0 -1.0, uv.y * 2.0 -1.0, depth_fact * 2.0 -1.0, 1.0 ); // conv todo de -1 a 1
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w ;

	float shadow_factor = get_shadow_factor( world_position, u_shadow_viewproj, u_shadow_bias, u_shadow_map, u_cast_shadows, u_show_shadows);

	vec3 light = vec3(0.0);
	vec3 color = vec3(0.0);
	//color = degamma( albedo.xyz); 
	color =  albedo.xyz; 

	float metalness = albedo.a ;
	float roughness = normal.a;
	vec3 L = normalize(u_light_position - world_position);
	float NoL = max( dot(N,L) , 0.0);

	float att_factor =  compute_attfactor( u_light_position, world_position, u_light_maxdist );
	//vec3 diffspecular_light = get_diffspecular_light(  L ,  u_light_vector,  u_light_position,  u_camera_position,  N,  metalness, roughness ,  color,  NoL );		
	
	float spotFactor = 1.0;

	if (u_light_type == 2){ // spot light

		float spotCosine = dot( normalize( u_light_vector), -L ); //como alineado entre -L y light_direction
		spotCosine = max(spotCosine, 0.0 ); 
		spotFactor = 0.0;
		if ( spotCosine >= u_light_spotCosineCutoff ){
			spotFactor = pow( spotCosine , u_light_spotExponent ) ;
		}
	}
	// If it's a point light, it will have spotFactor = 1
	light +=  spotFactor * att_factor * NoL  * u_light_color * u_light_intensity * shadow_factor; //diffspecular_light
	
	color.xyz *= light;
	gl_FragData[0] = vec4(color, 1.0 ) ;
	
}

// -------------------------------------------------------------------------------------------------------------------------


\applyHDRgamma.fs

varying vec2 v_uv;
uniform sampler2D u_texture;
#include "get_gamma_functions"

//out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec3 color = texture2D( u_texture, uv ).xyz ;
	color = gamma(color);
	color = linearToneMapping(color);
	gl_FragColor = vec4( color, 1.0 ); 

}

// -------------------------------------------------------------------------------------------------------------------------

\ssao.fs

varying vec2 v_uv;

uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform mat4 u_viewprojection;
uniform mat4 u_inverse_viewprojection;
uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;
uniform vec2 u_camera_nearfar;

#include get_functions_utils
#define MAX_POINTS 256 
uniform vec3 u_points[MAX_POINTS];

//out vec4 FragColor;;

void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv + u_iRes * 0.5;

	//read depth from depth buffer
	float depth = texture2D( u_depth_texture, uv ).x;

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		gl_FragColor = vec4(1.0); 
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	vec3 normal = texture2D(u_normal_texture, uv ).xyz ;

	//to create the matrix33 to convert from tangent to world
	mat3 rotmat = cotangent_frame( normal, worldpos, v_uv );

	//lets use 64 samples
	const int samples = MAX_POINTS;
	int num = samples; //num samples that passed the are outside
	
	vec3 rotated_point = vec3(0.0);
	//for every sample around the point
	float pdepth = 0.0;
	vec4 proj = vec4(0.0);
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z_old = 0.0;
	float z_new = 0.0;
	float z_diff = 0.0;
	for( int i = 0; i < samples; ++i )
	{
		//rotate a point is easy
		rotated_point = rotmat * u_points[i];

		//compute is world position using the random
		vec3 point = worldpos + rotated_point * 10.0; // este 10 es el radio y lo podemos poner fuera

		//find the uv in the depth buffer of this point
		proj = u_viewprojection * vec4(point, 1.0); 
		proj.xy /= proj.w; //convert to clipspace from homogeneous

		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		pdepth = texture2D( u_depth_texture, proj.xy ).x;

		// linealizar la depth 
		
		z_old = n * (pdepth + 1.0) / (f + n - pdepth * (f - n));
		z_new = n * (proj.z + 1.0) / (f + n - proj.z * (f - n));
		z_diff = z_new - z_old;
		
		//compare true depth with its depth
		if( z_old < z_new && z_diff > 0.001) //if true depth smaller, is inside

			//podemos aรฑadir, si el punto esta detras, a demas esta muy lejos, mejor no tenerlo en cuenta 
			num--; //remove this point from the list of visible
			//Acumular cuantos pixeles que estaban detras que esta tapando y los quito...
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);

	gl_FragColor = vec4( ao ); // occure coherencia temporal, no debe cambiar entre frames siguientes...

	//FragColor = vec4( worldpos * 0.01, 1.0); ///
}


// -------------------------------------------------------------------------------------------------------------------------

\get_SHs_functions

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}


//  -------------------------------------------------------------------------------------------------------------------------

\get_irradiance_functions

vec3 computeNearestProbeIndex(vec3 u_irr_start, vec3 u_irr_end, vec3 u_irr_delta, vec3 world_position, float u_irr_normal_distance, vec3 N){
	//computing nearest probe index based on world position

	vec3 irr_range = u_irr_end - u_irr_start;

	vec3 irr_local_pos = clamp( world_position - u_irr_start + N * u_irr_normal_distance, vec3(0.0), irr_range );

	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;

	return irr_norm_pos;
}

float findProbeRowOfTexture( vec3 local_indices, vec3 u_irr_dims,  float u_num_probes){

	//compute in which row is the probe stored
	float row = local_indices.x + local_indices.y * u_irr_dims.x + local_indices.z * u_irr_dims.x * u_irr_dims.y;

	//find the UV.y coord of that row in the probes texture
	float row_uv = (row + 1.0) / (u_num_probes + 1.0); 

	return row_uv;
}

vec3 getIrradiance(vec3 local_indices, vec3 u_irr_dims, float u_num_probes, sampler2D u_probes_texture, vec3 N){
	
	float row_uv = findProbeRowOfTexture(local_indices, u_irr_dims, u_num_probes); 

	//fill the coefficients
	SH9Color sh;

	const float d_uvx = 1.0 / 9.0;
	
	for(int i = 0; i < 9; ++i)
	{
		vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		sh.c[i] = texture2D( u_probes_texture, coeffs_uv ).xyz;
	}

	vec3 irradiance = ComputeSHIrradiance( N, sh );

	return irradiance;
}

vec3 getIrradianceInterpolated(vec3 local_indices, vec3 irr_norm_pos, vec3 u_irr_dims, float u_num_probes, sampler2D u_probes_texture, vec3 N){
	//now we have the interpolation factors
	vec3 factors = irr_norm_pos - local_indices; 

	//local_indices points to Left, Bottom, Far
	vec3 indicesLBF = local_indices;

	// local_indices points Right, Bottom, Far
	vec3 indicesRBF = local_indices;
	indicesRBF.x += 1.0; //from left to right
	
	// local_indices points Left, Top, Far
	vec3 indicesLTF = local_indices;
	indicesLTF.y += 1.0;
	
	// local_indices points Right, Top, Far
	vec3 indicesRTF = local_indices;
	indicesRTF.x += 1.0;
	indicesRTF.y += 1.0;
	
	// local_indices points Left, Bottom, Near
	vec3 indicesLBN = local_indices;
	indicesLBN.z += 1.0;
	
	// local_indices points Right, Bottom, Near
	vec3 indicesRBN = local_indices;
	indicesRBN.x += 1.0;
	indicesRBN.z += 1.0;

	// local_indices points Left, Top, Near
	vec3 indicesLTN = local_indices;
	indicesLTN.y += 1.0;
	indicesLTN.z += 1.0;

	
	// local_indices points Right, Top, Near
	vec3 indicesRTN = local_indices;
	indicesRTN.x += 1.0;
	indicesRTN.y += 1.0;
	indicesRTN.z += 1.0;

	//compute irradiance for every corner
	vec3 irrLBF = getIrradiance( indicesLBF, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrRBF = getIrradiance( indicesRBF, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrLTF = getIrradiance( indicesLTF, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrRTF = getIrradiance( indicesRTF, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrLBN = getIrradiance( indicesLBN, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrRBN = getIrradiance( indicesRBN, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrLTN = getIrradiance( indicesLTN, u_irr_dims, u_num_probes, u_probes_texture, N );
	vec3 irrRTN = getIrradiance( indicesRTN, u_irr_dims, u_num_probes, u_probes_texture, N );

	vec3 irrTF = mix( irrLTF, irrRTF, factors.x );
	vec3 irrBF = mix( irrLBF, irrRBF, factors.x );
	vec3 irrTN = mix( irrLTN, irrRTN, factors.x );
	vec3 irrBN = mix( irrLBN, irrRBN, factors.x );

	vec3 irrT = mix( irrTF, irrTN, factors.z );
	vec3 irrB = mix( irrBF, irrBN, factors.z );

	vec3 irradiance = mix( irrB, irrT, factors.y );
	
	return irradiance;
}


// -------------------------------------------------------------------------------------------------------------------------


\probe.fs

//varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;

#include "get_SHs_functions"
uniform vec3 u_coeffs[9];

//out vec4 FragColor;

void main()
{
	
	vec3 N = normalize(v_normal);

	
	SH9Color sh;
	sh.c[0] = u_coeffs[0];
	sh.c[1] = u_coeffs[1];
	sh.c[2] = u_coeffs[2];
	sh.c[3] = u_coeffs[3];
	sh.c[4] = u_coeffs[4];
	sh.c[5] = u_coeffs[5];
	sh.c[6] = u_coeffs[6];
	sh.c[7] = u_coeffs[7];
	sh.c[8] = u_coeffs[8];
	
	// for degub:
	/* 
	SH9Color sh;
	#include "find_probe_row_of_texture"
	
	//fill the coefficients
	const float d_uvx = 1.0 / 9.0;
	for(int i = 0; i < 9; ++i)
	{
		vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
		sh.c[i] = texture2D( u_probes_texture, coeffs_uv ).xyz;
	}
	*/

	vec3 irradiance = ComputeSHIrradiance( N, sh );
	
	
	gl_FragColor.xyz = irradiance;
}

// -------------------------------------------------------------------------------------------------------------------------

\irradiance_sh.fs

#include "get_SHs_functions"
#include "get_irradiance_functions"
#include "get_irradiance_uniforms"

uniform vec2 u_iRes;
uniform mat4 u_inverse_viewprojection;
uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_color_texture;


void main()
{
	
	// we can extract uvs from pixel screenpos
	vec2 uv = gl_FragCoord.xy * u_iRes.xy ;

	//vec3 N = normalize(v_normal);
	vec3 N = texture2D(u_normal_texture, uv).xyz;

	vec3 color = texture2D(u_color_texture, uv).xyz;
	
	//reconstruct world position from depth and inv. viweproj
	vec4 depth = texture2D( u_depth_texture, uv ); // mirar terminar como esto
	float depth_fact = depth.x ;
	vec4 screen_pos = vec4( uv.x *2.0 -1.0, uv.y * 2.0 -1.0, depth_fact*2.0-1.0, 1.0 ); // conv todo de -1 a 1
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w ;

	//Compute the position of the nearest probe to extract its sh coefficients
	vec3 irr_norm_pos = computeNearestProbeIndex(u_irr_start, u_irr_end, u_irr_delta, world_position, u_irr_normal_distance, N);

	//floor instead of round
	vec3 local_indices = floor(irr_norm_pos);
	
	// Compute the irradiance
	//vec3 irradiance = getIrradianceInterpolated(local_indices, irr_norm_pos, u_irr_dims, u_num_probes, u_probes_texture, N);
	vec3 irradiance = getIrradiance(local_indices, u_irr_dims, u_num_probes, u_probes_texture, N); //This is the uninterpolated version
	
	gl_FragColor.xyz = color * irradiance;
}

// -------------------------------------------------------------------------------------------------------------------------

\multi.fs

varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_color_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

//layout(location = 0) out vec4 FragColor;
//layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_color_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	gl_FragData[0] = color;
	gl_FragData[1] = vec4(N,1.0);
}

// -------------------------------------------------------------------------------------------------------------------------
\depth.fs

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
varying vec2 v_uv;
//out vec4 FragColor;

void main()
{
	//example of linearizing depthmap inside shader so we can show it on the screen
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture, v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	gl_FragColor = vec4(color);
}

// -------------------------------------------------------------------------------------------------------------------------
\instanced.vs



attribute vec3 a_vertex;
attribute vec3 a_normal;
attribute vec2 a_coord;

attribute mat4 u_model;

uniform vec3 u_camera_position; // camera eye

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
varying vec3 v_position;
varying vec3 v_world_position;
varying vec3 v_normal;
varying vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\volumetric_rendering.fs

varying vec2 v_uv;

uniform vec3 u_camera_position;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform float u_air_density;

#include "get_lights_uniforms"
#include "get_lights_functions"
#include "get_textures_uniforms"
#include "get_gamma_functions"
#include "get_shadow_uniforms"
#include "get_shadow_functions"


#define SAMPLES 64

void main()
{
	// we can extract uvs from pixel screenpos
	vec2 uv = gl_FragCoord.xy * u_iRes.xy ;

	//-----read depth textures from gbuffers---
	vec4 depth = texture2D(u_depth_texture, uv);
	
	//reconstruct world position from depth and inv. viweproj
	float depth_fact = depth.x ;
	vec4 screen_pos = vec4( uv.x *2.0 -1.0, uv.y * 2.0 -1.0, depth_fact*2.0-1.0, 1.0 ); // conv todo de -1 a 1
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w ;

	// Compute the ray vector
	vec3 ray_dir = world_position - u_camera_position;
	float dist = length( ray_dir );
	ray_dir /= dist; // normalizing the vector

	dist = clamp(dist, 0.0, 550.0);

	// Initializing ray marching state
	float step_dist = dist / float(SAMPLES);
	vec3 current_pos = u_camera_position;
	vec3 ray_offset = ray_dir * step_dist;

	//how visible is the point at the end of the ray
	float transparency = 1.0;

	vec3 irradiance = vec3(0.0);


	// Ray-marching for loop
	for(int i = 0; i < SAMPLES; ++i)
	{
		//reduce visibility
		float pixel_transparency = u_air_density * step_dist;
		transparency -= pixel_transparency;

		//compute illumination in this point
		//...

		float att_factor = compute_attfactor(u_light_position, current_pos, u_light_maxdist);
		float shadow_factor = get_shadow_factor( current_pos, u_shadow_viewproj, u_shadow_bias, u_shadow_map, u_cast_shadows, u_show_shadows);
		
		//accumulate accordingly
		irradiance += u_light_color * pixel_transparency * u_light_intensity * shadow_factor;

		//advance to next position
		current_pos.xyz += ray_offset;

		if(transparency < 0.001){
			break;
		}
	}

	gl_FragColor = vec4(irradiance, transparency);
	
}

\compute_coc.fs
varying vec2 v_uv;

uniform float u_camera_aperture;
uniform float u_image_distance;
uniform vec2 u_focus_point;
uniform float u_max_coc;
uniform sampler2D u_depth_texture;
uniform vec2 u_camera_nearfar;
uniform float u_plane_in_focus;

void main()
{	
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;

	/*
	// It finds the distance of the point in the middle to force the focus at that distance. However, for some reason is not working this approach. 
	// Plane in focus
	float plane_in_focus = texture2D(u_depth_texture, floor(u_focus_point) + 0.005).x;
	plane_in_focus = n * (plane_in_focus + 1.0) / (f + n - plane_in_focus * (f - n)); // Linearizing and get the truth z
	plane_in_focus = plane_in_focus*(f-n) + n; // Setting values from [near, far]
	*/
	float plane_in_focus = u_plane_in_focus;	


	// object distance
	float object_distance = texture2D(u_depth_texture, v_uv).x;
	object_distance = n * (object_distance + 1.0) / (f + n - object_distance * (f - n)); // Linearizing and get the truth z
	object_distance = object_distance*(f-n) + n; // Setting values from [near, far]

	// Compute focal length
	float focal_length = plane_in_focus * object_distance / (plane_in_focus + object_distance);

	float CoC = u_camera_aperture * focal_length * (plane_in_focus - object_distance);
	CoC /= (object_distance * (plane_in_focus - focal_length));
	CoC = abs(CoC);

	// to avoid large values of CoC we clamp it 
	float normalized_CoC = CoC / u_max_coc; // Passing from 0 to 1
	normalized_CoC = clamp(normalized_CoC, 0.0, 1.0);

	gl_FragData[0].xyz = vec3(normalized_CoC);

	// To see where is the center point
	/*float radius_center = 10.0;
	if(length(gl_FragCoord.xy - u_focus_point) <= radius_center){
		gl_FragData[0].xyz = vec3(1.0, 0.0, 0.0);
	}*/

}


\dof.fs
varying vec2 v_uv;

uniform float u_max_coc;
uniform sampler2D u_illumination_texture;
uniform sampler2D u_coc_texture;
uniform vec2 u_iRes;

#define MAX_COC 20

void main()
{	
	vec3 sum_samples = vec3(0.0);

	// Denormalizing u_coc_texture since it has values in range [0, 1]. We want to have [0, u_max_coc]
	float max_coc_factor = texture2D(u_coc_texture, v_uv).x; // it's in range [0,1]
	float max_coc = max_coc_factor * u_max_coc;

	// Counter of the number of samples used
	float num_samples = 0.0;

	for(int i = 0; i < MAX_COC; i++){
		if (i > int(max_coc)){
			break;
		}

		for(int j = 0; j < MAX_COC; j++){
			if(j > int(max_coc)){
				break;
			}
			// Find the uvs of the neightbour pixels
			vec2 uv_sample = vec2(0.0);
			uv_sample.x = (gl_FragCoord.x + float(i) - max_coc/2.0) * u_iRes.x ;
			uv_sample.y = (gl_FragCoord.y + float(j) - max_coc/2.0) * u_iRes.y ;
			
			// Sum the value of the neightbour pixels
			sum_samples += texture2D(u_illumination_texture, uv_sample).xyz;

			// Update the number of samples used
			num_samples ++;
		}
	}

	vec3 blured_pixel = sum_samples / num_samples;
	
	// In the case that the circle of confusion is equal to zero, we choose the pixel
	if (num_samples == 0.0){
		blured_pixel = texture2D(u_illumination_texture, v_uv).xyz;
	}

	gl_FragColor = vec4(blured_pixel, max_coc_factor);

}



// -------------------------------------------------------------------------------------------------------------------------

\decal.fs

#include "get_textures_uniforms"
uniform sampler2D u_decal_texture;
uniform int u_decal_texture_type;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
// we need the inv of the model to be able pass from world space to obj decal space
uniform mat4 u_iModel;

void main()
{
	// we need to extract uvs from pixel screenpos, no use uvs of the cube
	vec2 uv = gl_FragCoord.xy * u_iRes.xy ;

	vec4 albedo = texture2D(u_color_texture, uv);
	vec4 normal = texture2D(u_normal_texture, uv);
	vec4 extra = texture2D(u_extra_texture, uv);
	vec4 depth = texture2D(u_depth_texture, uv);
	
	//ignore pixels in the background
	float depth_fact = depth.x ;
	if( depth_fact >= 1.0)
		discard;

	//reconstruct world position from depth and inv. viweproj
	vec4 screen_pos = vec4( uv.x *2.0 -1.0, uv.y * 2.0 -1.0, depth_fact*2.0-1.0, 1.0 ); // conv todo de -1 a 1
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w ;

	//Convert to decal space by inverse model of the decal 
	vec3 localpos = (u_iModel * vec4(world_position, 1.0) ).xyz;
	
	//use x and z to compute uvs where fetch the pixel , from -1,1 to 0,1
	uv = (localpos.xz / 2.0) + vec2(0.5);
	//check if its of out of the range[0,1] to avoid projecting points outside the cube[0,1] of the decal
	if(uv.x < 0.0 || uv.x > 1.0 || uv.y < 0.0 || uv.y > 1.0)
		discard;

	vec4 decal = texture2D(u_decal_texture, uv);
	//discard pixels in decal_texture that have transparency
	if(decal.a < 0.5)
		discard;
	
	if (u_decal_texture_type == 0){
		albedo.xyz = decal.xyz;
	}
	else if (u_decal_texture_type == 1){
		normal.xyz = decal.xyz;
	}

	//albedo = vec4(1, 0, 0, 1);
	gl_FragData[0] = albedo ;
	gl_FragData[1] = normal ;
	gl_FragData[2] = extra ;
	
}

// -------------------------------------------------------------------------------------------------------------------------
\skybox.fs

varying vec3 v_world_position; 

uniform samplerCube u_texture;
uniform vec3 u_camera_position;
//out vec4 FragColor;

void main()
{
	vec3 V = v_world_position - u_camera_position;
	gl_FragColor = textureCube( u_texture, V);
	
} 

// -------------------------------------------------------------------------------------------------------------------------
\reflection_probe.fs

varying vec3 v_world_position; 
varying vec3 v_normal;

uniform samplerCube u_reflection_texture;
uniform vec3 u_camera_position;

//out vec4 FragColor;

void main()
{	


	vec3 N = normalize( v_normal);
	vec3 V = normalize( u_camera_position - v_world_position) ;

	vec3 R = reflect( - V , N);


	//compute the reflection 
	vec3 reflection = textureLod( u_reflection_texture, R, 0.0 ).xyz;

	gl_FragColor = vec4( reflection , 1.0 ); //vec4(1,0,0,1); //
	
} 

//---------------------------------------------------------------------------------------------------------------------------

\reflection_forward.fs

varying vec3 v_world_position; 
varying vec3 v_normal;
varying vec2 v_uv;


uniform samplerCube u_reflection_texture;
uniform sampler2D u_metallic_roughness_texture;
uniform vec3 u_camera_position;


//out vec4 FragColor;

void main()
{	

	
	vec3 N = normalize( v_normal);
	vec3 V = normalize( u_camera_position - v_world_position) ;

	vec3 R = reflect( - V , N);

	vec4 metallic_roughness = texture2D(u_metallic_roughness_texture, v_uv);
	
	float roughness = metallic_roughness.g;
	float metalness = metallic_roughness.b;


	//compute the reflection 
	vec3 reflection = textureLod( u_reflection_texture, R, roughness * 5.0 ).xyz;

	//set the metalness as alpha
	gl_FragColor = vec4( reflection , metalness);  // vec4(1,0,0,1); //
	
} 


// -------------------------------------------------------------------------------------------------------------------------
